{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0adb4e19",
   "metadata": {},
   "source": [
    "## Combined Summarization Dataset\n",
    "\n",
    "This dataset combines two previously created entity-centric summarization datasets:\n",
    "\n",
    "- `entity_to_abstracts.jsonl`: abstracts linked to **single** biomedical entities.\n",
    "- `multi_entity_to_abstracts.jsonl`: abstracts linked to **multiple** biomedical entities.\n",
    "\n",
    "Each entry includes:\n",
    "- A `pmid` (PubMed ID)\n",
    "- A list of `entities` associated with the abstract\n",
    "- The full `abstract` text\n",
    "- A generated `input` field used as the **summarization prompt** (based on entity or entity combination)\n",
    "- A `target` field containing the **title of the article**, used as the **summary**\n",
    "\n",
    "We merged these two files and **removed fully identical records** — i.e., duplicate pairs of `(input, target)` — while **preserving multiple unique prompts per abstract**. This ensures rich semantic diversity and maintains the connection between entities and content.\n",
    "\n",
    "---\n",
    "\n",
    "### Why Not Use the Vanilla Summarization Dataset?\n",
    "\n",
    "In early experiments, we created a \"vanilla\" summarization dataset where:\n",
    "\n",
    "- The `input` was the **full abstract**\n",
    "- The `target` was the **title** of the article\n",
    "\n",
    "This setup has some limitations:\n",
    "\n",
    "- It encourages the model to generate short titles, not true abstractive summaries\n",
    "- It ignores the valuable **entity-level information** we've extracted\n",
    "- It doesn't allow conditional summarization based on specific biomedical concepts\n",
    "\n",
    "---\n",
    "\n",
    "### Why Use This Dataset Instead?\n",
    "\n",
    "- Uses **entities as input prompts**, aligning with biomedical summarization use cases\n",
    "- More flexible: can create summaries **targeted to specific topics** (e.g. “immune checkpoint inhibitors” or “quality of life”)\n",
    "- Retains multiple valid prompts for the same abstract, enhancing training diversity\n",
    "- Suitable for **future RAG pipelines** or **multi-input summarization tasks**\n",
    "\n",
    "This dataset now serves as the **primary source for training biomedical summarization models**, including T5 and BART.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80e092",
   "metadata": {
    "vscode": {
     "languageId": "pip-requirements"
    }
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if you are using Google Colab and want to retreive the data from your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "\n",
    "# Paths to the two datasets\n",
    "entity_file = \"/content/drive/MyDrive/biomedical_text_generation/data/training/summarization/entity_to_abstracts.jsonl\"\n",
    "multi_entity_file = \"/content/drive/MyDrive/biomedical_text_generation/data/training/summarization/multi_entity_to_abstracts.jsonl\"\n",
    "\n",
    "# Load both datasets into a combined list\n",
    "all_samples = []\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        return list(reader)\n",
    "\n",
    "all_samples += load_jsonl(entity_file)\n",
    "all_samples += load_jsonl(multi_entity_file)\n",
    "\n",
    "print(f\"Total loaded samples (before deduplication): {len(all_samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c565b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates using a set of (input, output) tuples\n",
    "seen = set()\n",
    "unique_samples = []\n",
    "\n",
    "for sample in all_samples:\n",
    "    pair = (sample[\"input\"], sample[\"output\"])\n",
    "    if pair not in seen:\n",
    "        seen.add(pair)\n",
    "        unique_samples.append(sample)\n",
    "\n",
    "print(f\"Samples after deduplication: {len(unique_samples)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save combined dataset\n",
    "output_path = \"/content/drive/MyDrive/biomedical_text_generation/data/training/summarization/combined_deduplicated.jsonl\"\n",
    "\n",
    "with jsonlines.open(output_path, mode='w') as writer:\n",
    "    writer.write_all(unique_samples)\n",
    "\n",
    "print(\"✅ Combined dataset saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9afb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some statistics\n",
    "from collections import Counter\n",
    "\n",
    "# How many pmids do we have?\n",
    "pmid_counts = Counter([s[\"pmid\"] for s in unique_samples])\n",
    "print(\"Unique abstracts (pmids):\", len(pmid_counts))\n",
    "print(\"Average prompts per abstract:\", round(len(unique_samples) / len(pmid_counts), 2))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
