{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be2620ee",
   "metadata": {},
   "source": [
    "# Entity-to-Abstract Dataset Creation\n",
    "\n",
    "##  Purpose\n",
    "\n",
    "The goal of this notebook is to create a training dataset for **biomedical text generation**, where the model learns to generate or summarize abstracts based on **biomedical entities**.\n",
    "\n",
    "This can be used to train a model to:\n",
    "- generate relevant scientific text about a specific medical concept,\n",
    "- retrieve or summarize known findings about a disease, treatment, or biological process.\n",
    "\n",
    "### Example:\n",
    "- **Input (Prompt):** `\"Summarize findings about immune checkpoint inhibitors.\"`\n",
    "- **Target (Output):** `\"Immune checkpoint inhibitors have emerged as a promising therapy for various types of cancer, particularly in non-small cell lung cancer...\"`\n",
    "\n",
    "---\n",
    "\n",
    "##  Methodology\n",
    "\n",
    "We use the preprocessed dataset (`abstracts_with_entities.json`) where each abstract is already annotated with a list of extracted biomedical entities.\n",
    "\n",
    "We will:\n",
    "1. Load the enriched dataset.\n",
    "2. For each abstract, create one or more `(entity â†’ abstract)` training pairs.\n",
    "3. Store the generated dataset in a format suitable for training (e.g. JSONL, CSV, etc.).\n",
    "\n",
    "Each training example will consist of:\n",
    "- `input`: a templated prompt such as `\"Summarize findings about {entity}.\"`\n",
    "- `output`: the corresponding abstract\n",
    "\n",
    "This method assumes that abstracts are informative with respect to the mentioned entities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a32be4d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76903781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only if you are using Google Colab and want to retreive the data from your Google Drive.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efd1eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load the enriched abstracts that include entities\n",
    "with open(\"/content/drive/MyDrive/biomedical_text_generation/data/enriched/abstracts_with_entities.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total abstracts loaded: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af6b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Confirm structure\n",
    "df[[\"pmid\", \"title\", \"entities\", \"abstract\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac393c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store generated training examples here\n",
    "training_pairs = []\n",
    "\n",
    "# Loop through all abstracts\n",
    "for entry in data:\n",
    "    abstract = entry[\"abstract\"]\n",
    "    pmid = entry.get(\"pmid\", None)\n",
    "    for entity in entry[\"entities\"]:\n",
    "        # Create a templated prompt\n",
    "        prompt = f\"Summarize findings about {entity}.\"\n",
    "        training_pairs.append({\n",
    "            \"input\": prompt,\n",
    "            \"output\": abstract,\n",
    "            \"pmid\": pmid,\n",
    "            \"entity\": entity  # optional: to trace which entity was used\n",
    "        })\n",
    "\n",
    "print(f\"Generated {len(training_pairs)} training pairs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8a0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "\n",
    "# Create output folder\n",
    "output_path = \"/content/drive/MyDrive/biomedical_text_generation/data/training_data/summarization\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Save as JSON Lines (one JSON object per line)\n",
    "with jsonlines.open(os.path.join(output_path, \"entity_to_abstract.jsonl\"), mode=\"w\") as writer:\n",
    "    writer.write_all(training_pairs)\n",
    "\n",
    "print(\"Saved dataset to entity_to_abstract.jsonl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
