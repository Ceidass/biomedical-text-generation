{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0d22831",
   "metadata": {},
   "source": [
    "## Keyword-to-Abstract Generation Dataset\n",
    "\n",
    "This dataset is created for training biomedical text generation models using high-level **keywords or topics** as prompts.\n",
    "\n",
    "Each data point contains:\n",
    "- A **keyword** that was used to collect relevant abstracts\n",
    "- A **PubMed ID (pmid)** for reference\n",
    "- An **input prompt** like:  \n",
    "  `\"Write a biomedical paragraph about cancer immunotherapy.\"`\n",
    "- A **target**, which is the corresponding full abstract\n",
    "\n",
    "### Why this dataset?\n",
    "\n",
    "- Enables training **generative models** to create biomedical content based on research topics\n",
    "- Useful in real-world biomedical applications, such as:\n",
    "  - Automated literature writing\n",
    "  - Assisting domain experts with text generation\n",
    "  - Foundation for future **retrieval-augmented generation** (RAG)\n",
    "\n",
    "This dataset complements other variants (e.g., entity-based summarization and QA) and adds topic-level flexibility to biomedical text generation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e26bfc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e235196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27906037",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the raw folder path\n",
    "raw_folder_path = \"/content/drive/MyDrive/biomedical_text_generation/data/raw/\"\n",
    "\n",
    "# List all JSON files in the raw folder\n",
    "raw_files = [f for f in os.listdir(raw_folder_path) if f.endswith(\".json\")]\n",
    "\n",
    "# Dictionary to hold data per keyword\n",
    "keyword_to_abstracts = {}\n",
    "\n",
    "# Load each keyword file\n",
    "for filename in tqdm(raw_files):\n",
    "    keyword = filename.replace(\".json\", \"\")\n",
    "    full_path = os.path.join(raw_folder_path, filename)\n",
    "    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        keyword_to_abstracts[keyword] = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(keyword_to_abstracts)} keyword files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38de74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading cleaned dataset (where we have the clean titles/abstracts)\n",
    "cleaned_path = \"/content/drive/MyDrive/biomedical_text_generation/data/cleaned/all_abstracts_cleaned.json\"\n",
    "\n",
    "with open(cleaned_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    cleaned_abstracts = json.load(f)\n",
    "\n",
    "# Map from pmid to abstract\n",
    "pmid_to_cleaned = {entry[\"pmid\"]: entry for entry in cleaned_abstracts}\n",
    "\n",
    "# Final collection with combined data\n",
    "keyword_generation_dataset = []\n",
    "\n",
    "# For every keyword and the list with its abstracts\n",
    "for keyword, entries in keyword_to_abstracts.items():\n",
    "    for entry in entries:\n",
    "        pmid = entry.get(\"pmid\")\n",
    "        if not pmid:\n",
    "            continue\n",
    "\n",
    "        cleaned_entry = pmid_to_cleaned.get(pmid)\n",
    "        if not cleaned_entry:\n",
    "            continue\n",
    "\n",
    "        keyword_generation_dataset.append({\n",
    "            \"pmid\": pmid,\n",
    "            \"keyword\": keyword,\n",
    "            \"title\": cleaned_entry[\"title\"],\n",
    "            \"abstract\": cleaned_entry[\"abstract\"]\n",
    "        })\n",
    "\n",
    "print(f\"Final dataset size: {len(keyword_generation_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd3b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prompt creation: Ask from the model to write abstract for a keyword\n",
    "def create_prompt(keyword):\n",
    "    return f\"Write an abstract about {keyword}.\"\n",
    "\n",
    "# Preparing the final examples\n",
    "text_gen_data = []\n",
    "\n",
    "for item in keyword_generation_dataset:\n",
    "    prompt = create_prompt(item[\"keyword\"])\n",
    "    text_gen_data.append({\n",
    "        \"pmid\": item[\"pmid\"],\n",
    "        \"keyword\": item[\"keyword\"],\n",
    "        \"input\": prompt,\n",
    "        \"target\": item[\"abstract\"]\n",
    "    })\n",
    "\n",
    "print(f\"Prepared {len(text_gen_data)} prompt-based examples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e3832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if does not exist\n",
    "output_dir = \"../../../../data/training/text_gen\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Output path\n",
    "output_path = os.path.join(output_dir, \"keywords_to_text.jsonl\")\n",
    "\n",
    "# Saving\n",
    "with jsonlines.open(output_path, mode=\"w\") as writer:\n",
    "    writer.write_all(text_gen_data)\n",
    "\n",
    "print(f\"Saved {len(text_gen_data)} examples to:\")\n",
    "print(output_path)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
