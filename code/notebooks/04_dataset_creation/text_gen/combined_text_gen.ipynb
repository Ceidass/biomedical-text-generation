{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0290194",
   "metadata": {},
   "source": [
    "# Combine Text Generation Datasets\n",
    "\n",
    "This notebook merges all previously created text generation datasets into a unified dataset for training biomedical text generation models (e.g., T5, BART).\n",
    "\n",
    "### Source Files:\n",
    "- `entities_to_text.jsonl`\n",
    "- `multi_entities_to_text.jsonl`\n",
    "- `keywords_to_text.jsonl`\n",
    "- `multi_keywords_to_text.jsonl`\n",
    "- `key_ent_to_text.jsonl`\n",
    "\n",
    "Each dataset contains:\n",
    "- `pmid`: PubMed ID of the abstract\n",
    "- `input`: The text prompt (e.g., entity, keyword)\n",
    "- `output`: The target abstract\n",
    "\n",
    "### Goal:\n",
    "- Merge all files\n",
    "- Remove duplicates (based on identical `input` and `output`)\n",
    "- Save to: `data/training/text_gen/combined_text_gen.jsonl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beedb892",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9296515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38694bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jsonlines\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb9ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to individual datasets\n",
    "base_path = \"/content/drive/MyDrive/biomedical_text_generation/data/training/text_gen\"\n",
    "\n",
    "input_files = [\n",
    "    \"entity_to_text.jsonl\",\n",
    "    \"multi_entity_to_text.jsonl\",\n",
    "    \"keywords_to_text.jsonl\",\n",
    "    \"multi_keywords_to_text.jsonl\",\n",
    "    \"keywords_entities_to_text.jsonl\"\n",
    "]\n",
    "\n",
    "input_paths = [os.path.join(base_path, fname) for fname in input_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all entries from the jsonl files\n",
    "all_entries = []\n",
    "\n",
    "for path in input_paths:\n",
    "    with jsonlines.open(path) as reader:\n",
    "        for obj in reader:\n",
    "            all_entries.append(obj)\n",
    "\n",
    "print(f\"Total entries before deduplication: {len(all_entries)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove exact duplicates based on (input, output)\n",
    "unique = {}\n",
    "for entry in all_entries:\n",
    "    key = (entry[\"input\"], entry[\"target\"])\n",
    "    unique[key] = entry  # overwrites duplicates\n",
    "\n",
    "deduplicated = list(unique.values())\n",
    "print(f\"Entries after deduplication: {len(deduplicated)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output path\n",
    "output_path = os.path.join(base_path, \"combined_text_gen.jsonl\")\n",
    "\n",
    "# Save to jsonl\n",
    "with jsonlines.open(output_path, mode=\"w\") as writer:\n",
    "    writer.write_all(deduplicated)\n",
    "\n",
    "print(f\" Combined dataset saved to:\\n{output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
